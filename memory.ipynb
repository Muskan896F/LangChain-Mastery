{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "823a3d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f01beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97c216d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10ec9968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5018f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\",\"input\"],\n",
    "    template=\"\"\"\n",
    "You are a friendly chatbot having a conversation with a human.\n",
    "Previous conversation:\n",
    "{chat_history}\n",
    "New human input:{input}\n",
    "Response:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c25f594",
   "metadata": {},
   "source": [
    "### **Buffer Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a1831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "buffer_memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=buffer_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21ad098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = conversation.invoke(input=\"Hello, how are you?, My name is Muskan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "514e365a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Hello, how are you?, My name is Muskan',\n",
       " 'chat_history': [HumanMessage(content='Hello, how are you?, My name is Muskan', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hello Muskan! I'm just a chatbot, so I don't have feelings, but I'm here to chat with you. How can I assist you today?\", additional_kwargs={}, response_metadata={})],\n",
       " 'text': \"Hello Muskan! I'm just a chatbot, so I don't have feelings, but I'm here to chat with you. How can I assist you today?\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86ca1c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = conversation.invoke(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my name?',\n",
       " 'chat_history': [HumanMessage(content='Hello, how are you?, My name is Muskan', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hello Muskan! I'm just a chatbot, so I don't have feelings, but I'm here to chat with you. How can I assist you today?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Your name is Muskan.', additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'Your name is Muskan.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa0a4afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Muskan.\n"
     ]
    }
   ],
   "source": [
    "print(response2[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d51fce",
   "metadata": {},
   "source": [
    "### **Buffer window Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fff98c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8532\\37956945.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  window_memory = ConversationBufferWindowMemory(k=2)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationChain\n",
    "window_memory = ConversationBufferWindowMemory(k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abea605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_conv=ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=window_memory,\n",
    "    verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "960cf09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What I am \n",
      "AI: I'm sorry, could you please clarify your question? Are you asking what specific tasks or projects you are currently working on as a data scientist?\n",
      "Human: What I am doing? \n",
      "AI: Based on your previous question, it seems like you are seeking information about your current role or activities as a data scientist. If you provide more details or context, I can provide a more specific answer.\n",
      "Human: Hello, how are you?, My name is Muskan\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What I am doing? \n",
      "AI: Based on your previous question, it seems like you are seeking information about your current role or activities as a data scientist. If you provide more details or context, I can provide a more specific answer.\n",
      "Human: Hello, how are you?, My name is Muskan\n",
      "AI: Hello Muskan! I'm doing well, thank you for asking. It's nice to meet you. How can I assist you today?\n",
      "Human: I am a data scientist\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, how are you?, My name is Muskan\n",
      "AI: Hello Muskan! I'm doing well, thank you for asking. It's nice to meet you. How can I assist you today?\n",
      "Human: I am a data scientist\n",
      "AI: That's great to hear, Muskan! As a data scientist, you likely work with large datasets to extract valuable insights and make data-driven decisions. Do you have any specific questions or topics you'd like to discuss related to data science?\n",
      "Human: My age 26\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = window_conv.predict(input=\"Hello, how are you?, My name is Muskan\")\n",
    "response2 =window_conv.predict(input=\"I am a data scientist\")\n",
    "response4 = window_conv.predict(input=\"My age 26\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46329368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What I am doing?\n",
      "AI: As a data scientist, you may be working on projects such as predictive modeling, data visualization, machine learning, or statistical analysis. You might be using programming languages like Python or R, and tools like Jupyter Notebook or Tableau. Your goal is to extract valuable insights from data to help organizations make data-driven decisions. Is there a specific area within data science that you are currently focusing on?\n",
      "Human: What I am \n",
      "AI: I'm sorry, could you please clarify your question? Are you asking what specific tasks or projects you are currently working on as a data scientist?\n",
      "Human: What I am doing? \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response3 = window_conv.predict(input=\"What I am doing? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "115817ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: I am a data scientist\n",
      "AI: That's great to hear, Muskan! As a data scientist, you likely work with large datasets to extract valuable insights and make data-driven decisions. Do you have any specific questions or topics you'd like to discuss related to data science?\n",
      "Human: My age 26\n",
      "AI: Age is just a number! It's great to know a bit more about you, Muskan. Is there anything else you'd like to share or ask about?\n",
      "Human: What is my age? \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = window_conv.predict(input=\"What is my age? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e942402f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My age 26\n",
      "AI: Age is just a number! It's great to know a bit more about you, Muskan. Is there anything else you'd like to share or ask about?\n",
      "Human: What is my age? \n",
      "AI: I'm sorry, Muskan, but I do not have access to personal information like your age. If there is anything else you'd like to know or discuss, feel free to ask!\n",
      "Human: What is my name? \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = window_conv.predict(input=\"What is my name? \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4fbad2",
   "metadata": {},
   "source": [
    "## **Conversation Summary Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba34d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "summary_memory = ConversationSummaryMemory(llm=llm)\n",
    "summary_convo=ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=summary_memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c14c0a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, how are you , My name is Muskan ?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human introduces themselves as Muskan and asks the AI how it is doing. The AI responds positively and asks how it can assist Muskan.\n",
      "Human: Hello, how are you , I m a data scientist  ?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Muskan introduces themselves as a data scientist and asks the AI how it is doing. The AI responds positively and acknowledges Muskan's expertise in analyzing and interpreting data. It offers assistance to Muskan for any data-related tasks.\n",
      "Human: Hello, how are you , my age is 26  ?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Muskan introduces themselves as a data scientist and asks the AI how it is doing. The AI responds positively, acknowledges Muskan's expertise in analyzing and interpreting data, and offers assistance for any data-related tasks. The AI also notes Muskan's age of 26 and prompts for any specific topics of interest or discussion.\n",
      "Human: what is my age ?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Muskan introduces themselves as a data scientist and asks the AI how it is doing. The AI responds positively, acknowledges Muskan's expertise in analyzing and interpreting data, and offers assistance for any data-related tasks. The AI notes Muskan's age of 26 and prompts for any specific topics of interest or discussion, confirming Muskan's age and inquiring about any particular topics for discussion.\n",
      "Human: can you summarrize what you know\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Of course! I have access to a wide range of information on various topics such as science, technology, history, literature, and much more. I can provide summaries, explanations, definitions, and even generate creative content. Just let me know what you're interested in, and I'll do my best to assist you.\n"
     ]
    }
   ],
   "source": [
    "response = summary_convo.predict(input=\"Hello, how are you , My name is Muskan ?\")\n",
    "response1 = summary_convo.predict(input=\"Hello, how are you , I m a data scientist  ?\")\n",
    "response3 = summary_convo.predict(input=\"Hello, how are you , my age is 26  ?\")\n",
    "response2 = summary_convo.predict(input=\"what is my age ?\")\n",
    "\n",
    "response4 = summary_convo.predict(input=\"can you summarrize what you know\")\n",
    "print(response4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ea12b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Muskan introduces themselves as a data scientist and asks the AI how it is doing. The AI responds positively, acknowledging Muskan's expertise in analyzing and interpreting data and offers assistance for any data-related tasks. The AI notes Muskan's age of 26 and prompts for any specific topics of interest or discussion, confirming Muskan's age and inquiring about any particular topics for discussion. The human asks the AI to summarize what it knows, and the AI responds by mentioning its access to a wide range of information on various topics and its ability to provide summaries, explanations, definitions, and generate creative content.\n",
      "Human: can you summarrize what you know\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Certainly! I have access to a vast amount of information on numerous topics, including but not limited to science, technology, history, literature, art, and more. I can provide summaries, explanations, definitions, and even generate creative content based on the data available to me. Is there a specific topic you would like me to summarize for you?\n"
     ]
    }
   ],
   "source": [
    "response4 = summary_convo.predict(input=\"can you summarrize what you know\")\n",
    "print(response4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3226d7d8",
   "metadata": {},
   "source": [
    "### **Vector Retriver Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "965e5cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import  ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6eed463",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"Hello, how are you ?, My name is Muskan, I am a data scientist, I am 26 years old\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd176145",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(texts=text, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "memory = VectorStoreRetrieverMemory(\n",
    "    retriever=retriever\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2866eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_convo = ConversationChain(llm=llm,\n",
    "                                    memory=memory,\n",
    "                                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f2114de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Hello, how are you ?, My name is Muskan, I am a data scientist, I am 26 years old\n",
      "Human: What do you know about muskan?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Hello Muskan! It's nice to meet you. As a data scientist, I know that your name is Muskan and you are 26 years old. Unfortunately, I don't have any additional information about you beyond that. Is there anything else you'd like to share or ask about?\n"
     ]
    }
   ],
   "source": [
    "vector_response = vector_convo.predict(input=\"What do you know about muskan?\")\n",
    "print(vector_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ccefba",
   "metadata": {},
   "source": [
    "### **Combined Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3cf0a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa9e5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import (ConversationBufferMemory, ConversationSummaryMemory,CombinedMemory)\n",
    "llm = ChatOpenAI(temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b15f49eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_memory = ConversationBufferMemory(\n",
    "    memory_key=\"buffer_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96e8c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_memory = ConversationSummaryMemory(llm=llm, memory_key=\"summary_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62ad2b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\LangChain-Mastery\\LANGCHAIN\\Lib\\site-packages\\langchain\\memory\\combined.py:40: UserWarning: When using CombinedMemory, input keys should be so the input is known.  Was not set on chat_memory=InMemoryChatMessageHistory(messages=[]) return_messages=True memory_key='buffer_history'\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\LangChain-Mastery\\LANGCHAIN\\Lib\\site-packages\\langchain\\memory\\combined.py:40: UserWarning: When using CombinedMemory, input keys should be so the input is known.  Was not set on llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001F6F5F64610>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F6F5F04590>, root_client=<openai.OpenAI object at 0x000001F6F5ED9650>, root_async_client=<openai.AsyncOpenAI object at 0x000001F6F6075210>, temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********')) chat_memory=InMemoryChatMessageHistory(messages=[]) memory_key='summary_history'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "combined_memory = CombinedMemory(\n",
    "    memories=[buffer_memory, summary_memory],\n",
    "    memory_key=\"combined_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "095baae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"buffer_history\", \"summary_history\", \"input\"],\n",
    "    template=\"\"\"\n",
    "You are a helpful assistant.\n",
    "\n",
    "Recent conversation:\n",
    "{buffer_history}\n",
    "\n",
    "Summary:\n",
    "{summary_history}\n",
    "\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4f8e73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversion(user_input :str):\n",
    "    memory_vars =combined_memory.load_memory_variables({\"input\": user_input})\n",
    "\n",
    "    full_input ={\n",
    "        \"input\": user_input,\n",
    "        **memory_vars\n",
    "    }\n",
    "\n",
    "\n",
    "    prompt_str = prompt.format(**full_input)\n",
    "    response = llm.invoke(prompt_str)\n",
    "\n",
    "\n",
    "    combined_memory.save_context({\"input\": user_input}, {\"output\": response.content})\n",
    "\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a89e0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Muskan, I'm here to help you. How can I assist you today?\n",
      "That's great! How can I assist you with your work as a data scientist today?\n",
      "That's great to know! Is there anything specific you would like assistance with as a 26-year-old data scientist?\n",
      "Your name is Muskan.\n"
     ]
    }
   ],
   "source": [
    "print(run_conversion(\"Hello, how are you? My name is Muskan.\"))\n",
    "print(run_conversion(\"I am a data scientist.\"))\n",
    "print(run_conversion(\"I am 26 years old.\"))\n",
    "print(run_conversion(\"What is my name?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6c096b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are Muskan, a 26-year-old data scientist who is seeking assistance with their work in that field.\n"
     ]
    }
   ],
   "source": [
    "print(run_conversion(\"Summarize about me?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97f90898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The End\n"
     ]
    }
   ],
   "source": [
    "print(\"The End\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
