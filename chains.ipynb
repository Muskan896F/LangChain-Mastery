{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82bb8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c020b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40b4228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=\"What is the capital of {input}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1820f233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWhat is the capital of India?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7937098f",
   "metadata": {},
   "source": [
    "# SequentialChain  and SimpleSequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "130ddb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f267bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b983a788",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
    ")\n",
    "name_chain = LLMChain(llm = llm , prompt = prompt_template_name, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3ceb78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template=\"\"\"Suggest some menu items for {restaurant_name}\"\"\"\n",
    ")\n",
    "food_items_chain = LLMChain(llm = llm , prompt =prompt_template_items, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2df287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = SimpleSequentialChain(chains=[name_chain, food_items_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1afae279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI want to open a restaurant for Indian food. Suggest a fency name for this.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSuggest some menu items for \"Spice Palace\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "1. Spicy Chicken Tikka Masala\n",
      "2. Vegetable Biryani\n",
      "3. Lamb Vindaloo\n",
      "4. Paneer Butter Masala\n",
      "5. Tandoori Shrimp\n",
      "6. Aloo Gobi (potatoes and cauliflower in a spicy tomato sauce)\n",
      "7. Chicken Korma\n",
      "8. Masala Dosa\n",
      "9. Samosas\n",
      "10. Mango Lassi (yogurt drink)\n"
     ]
    }
   ],
   "source": [
    "content = chain.run(\"Indian\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa615280",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
    ")\n",
    "\n",
    "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29c5134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template=\"Suggest some menu items for {restaurant_name}.\"\n",
    ")\n",
    "\n",
    "food_items_chain =LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2380243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3374a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = SequentialChain(\n",
    "    chains = [name_chain, food_items_chain],\n",
    "    input_variables = ['cuisine'],\n",
    "    output_variables = ['restaurant_name', \"menu_items\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3578678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10516\\4145920963.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(chain({\"cuisine\": \"Indian\"}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Indian', 'restaurant_name': '\"Maharaja\\'s Spice Palace\"', 'menu_items': '1. Tandoori Chicken: Marinated chicken cooked in a traditional clay oven\\n2. Butter Chicken: Tender chicken cooked in a rich and creamy tomato-based sauce\\n3. Lamb Rogan Josh: Slow-cooked lamb in a spicy and aromatic curry\\n4. Vegetable Biryani: Fragrant basmati rice cooked with mixed vegetables and aromatic spices\\n5. Garlic Naan: Freshly baked bread topped with garlic and butter\\n6. Palak Paneer: Creamy spinach curry with chunks of paneer cheese\\n7. Chicken Tikka Masala: Grilled chicken in a creamy and flavorful tomato-based sauce\\n8. Chana Masala: Spiced chickpeas cooked in a tangy tomato sauce\\n9. Mango Lassi: A refreshing yogurt-based drink flavored with sweet mango\\n10. Gulab Jamun: Deep-fried milk dumplings soaked in a rose flavored sugar syrup.'}\n"
     ]
    }
   ],
   "source": [
    "print(chain({\"cuisine\": \"Indian\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba0dd8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story: In the year 2190, humanity had reached an unprecedented era of space exploration. Thanks to advancements in technology, humans were able to travel to distant galaxies and explore planets that were once thought to be unreachable.\n",
      "\n",
      "One such planet was Proxima Centauri b, a small rocky planet located in the habitable zone of the closest star to Earth. A team of astronauts was sent on a mission to explore this alien world and search for signs of life.\n",
      "\n",
      "As the spacecraft approached the planet, the crew marveled at the breathtaking views of the alien landscape below. They could see vast oceans, towering mountains, and lush forests stretching as far as the eye could see.\n",
      "\n",
      "Upon landing on the planet's surface, the crew donned their space suits and ventured out to explore. They were amazed by the strange and exotic plant life they encountered, with colors and shapes unlike anything they had ever seen before.\n",
      "\n",
      "As they delved deeper into the planet's interior, they stumbled upon a network of caves that seemed to stretch for miles. Inside, they discovered ancient artifacts and evidence of a long-lost civilization that had once inhabited the planet.\n",
      "\n",
      "Excited by their discoveries, the crew continued to explore, uncovering more secrets and mysteries hidden within Proxima Centauri b. They made contact with intelligent alien beings who welcomed them with open arms, eager to share their knowledge and culture with their new human friends.\n",
      "\n",
      "After months of exploration, the crew bid farewell to their new alien friends and returned to Earth, their heads filled with dreams of future expeditions and discoveries waiting to be made in the vast expanse of space.\n",
      "\n",
      "And so, the era of space exploration continued, with humanity pushing the boundaries of what was possible and reaching for the stars in search of new worlds and new adventures.\n",
      "Analysis: The main theme of this story is the exploration of the unknown and the endless possibilities that come with it. The astronauts embark on a journey to a distant planet, encountering new landscapes, plant life, and even intelligent alien beings. Their discoveries fuel their curiosity and desire to continue exploring the vast expanse of space. The story highlights the importance of pushing boundaries, seeking knowledge, and embracing new experiences in order to expand our understanding of the universe.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# First chain: Write a story\n",
    "story_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Write a short story about {topic}.\"\n",
    ")\n",
    "story_chain = LLMChain(llm=llm, prompt=story_prompt, output_key=\"story\")\n",
    "\n",
    "# Second chain: Analyze that story\n",
    "analysis_prompt = PromptTemplate(\n",
    "    input_variables=[\"story\"],\n",
    "    template=\"Analyze the following story and identify its main theme: {story}\"\n",
    ")\n",
    "analysis_chain = LLMChain(llm=llm, prompt=analysis_prompt, output_key=\"analysis\")\n",
    "\n",
    "# Combine both\n",
    "sequential_chain = SequentialChain(\n",
    "    chains=[story_chain, analysis_chain],\n",
    "    input_variables=[\"topic\"],\n",
    "    output_variables=[\"story\", \"analysis\"]\n",
    ")\n",
    "\n",
    "result = sequential_chain({\"topic\": \"space exploration\"})\n",
    "print(\"Story:\", result[\"story\"])\n",
    "print(\"Analysis:\", result[\"analysis\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167a037e",
   "metadata": {},
   "source": [
    "# Memory Based Chains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46fbf699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a5a38a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dc47347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10516\\2872752716.py:2: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation_chain = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "conversation_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58f2d2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: HI my name is Muskan \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: HI my name is Muskan \n",
      "AI: Hello Muskan! It's nice to meet you. How are you doing today?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: Your name is Muskan.\n"
     ]
    }
   ],
   "source": [
    "conversation_chain.run(input=\"HI my name is Muskan \")\n",
    "response = conversation_chain.run(input=\"What is my name?\")\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ede7fa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10516\\3519446282.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k=3, return_messages=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[]\n",
      "Human: Hi, my name is John.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hi, my name is John.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello John! It's nice to meet you. How can I assist you today?\", additional_kwargs={}, response_metadata={})]\n",
      "Human: I live in New York.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hi, my name is John.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello John! It's nice to meet you. How can I assist you today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='I live in New York.', additional_kwargs={}, response_metadata={}), AIMessage(content='New York is a vibrant and bustling city known for its diverse population, iconic landmarks such as the Statue of Liberty and Central Park, and world-class museums like the Metropolitan Museum of Art and the Museum of Modern Art. It is also a major financial and cultural hub, with Broadway theaters, Times Square, and a thriving culinary scene. Is there anything specific you would like to know or discuss about New York?', additional_kwargs={}, response_metadata={})]\n",
      "Human: My favorite color is blue.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hi, my name is John.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello John! It's nice to meet you. How can I assist you today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='I live in New York.', additional_kwargs={}, response_metadata={}), AIMessage(content='New York is a vibrant and bustling city known for its diverse population, iconic landmarks such as the Statue of Liberty and Central Park, and world-class museums like the Metropolitan Museum of Art and the Museum of Modern Art. It is also a major financial and cultural hub, with Broadway theaters, Times Square, and a thriving culinary scene. Is there anything specific you would like to know or discuss about New York?', additional_kwargs={}, response_metadata={}), HumanMessage(content='My favorite color is blue.', additional_kwargs={}, response_metadata={}), AIMessage(content='Blue is a popular color choice for many people due to its calming and soothing qualities. It is often associated with tranquility, trust, and reliability. Do you have a specific reason why blue is your favorite color, John?', additional_kwargs={}, response_metadata={})]\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: Your name is John.\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=3, return_messages=True)\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "conversation_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "conversation_chain.run(\"Hi, my name is John.\")\n",
    "conversation_chain.run(\"I live in New York.\")\n",
    "conversation_chain.run(\"My favorite color is blue.\")\n",
    "\n",
    "\n",
    "response = conversation_chain.run(\"What is my name?\")\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f656c998",
   "metadata": {},
   "source": [
    "# RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cb666c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: LangChain is a framework for developing applications powered by language models. It provides modules for working with language models.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "docs = [\n",
    "    \"LangChain is a framework for developing applications powered by language models.\",\n",
    "    \"It enables applications that are context-aware and can reason.\",\n",
    "    \"LangChain provides modules for working with language models.\"\n",
    "]\n",
    "\n",
    "vectorstore = FAISS.from_texts(docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "\n",
    "retrieval_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "query = \"What is LangChain?\"\n",
    "response = retrieval_chain.run(query)\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "712ee019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10516\\2179365055.py:14: LangChainDeprecationWarning: LangChain has introduced a method called `with_structured_output` thatis available on ChatModels capable of tool calling.You can read more about the method here: <https://python.langchain.com/docs/modules/model_io/chat/structured_output/>. Please follow our extraction use case documentation for more guidelineson how to do information extraction with LLMs.<https://python.langchain.com/docs/use_cases/extraction/>. If you notice other issues, please provide feedback here:<https://github.com/langchain-ai/langchain/discussions/18154>\n",
      "  extraction_chain = create_extraction_chain( llm = llm , schema = schema, verbose = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Extract and save the relevant entities mentioned in the following passage together with their properties.\n",
      "\n",
      "Only extract the properties mentioned in the 'information_extraction' function.\n",
      "\n",
      "If a property is not present and is not required in the function parameters, do not include it in the output.\n",
      "\n",
      "Passage:\n",
      "prince is 30 years old and enjoys reading and swimming.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: [{'name': 'prince', 'age': 30, 'hobbies': ['reading', 'swimming']}]\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_extraction_chain\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "\n",
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"age\": {\"type\": \"integer\"},\n",
    "        \"hobbies\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "    },\n",
    "    \"required\": [\"name\", \"age\"]\n",
    "}\n",
    "\n",
    "extraction_chain = create_extraction_chain( llm = llm , schema = schema, verbose = True)\n",
    "\n",
    "\n",
    "text = \"prince is 30 years old and enjoys reading and swimming.\"\n",
    "response=extraction_chain.run(text)\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f658863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The End\n"
     ]
    }
   ],
   "source": [
    "print(\"The End\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
